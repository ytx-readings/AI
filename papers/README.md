# AI Papers

## [LLM](./LLM/)

* [CMMLU: Measuring massive multitask language understanding in Chinese](./LLM/CMMLU.pdf)
* [CodeFuse-13B: A Pretrained Multi-lingual Code Large Language Model](./LLM/CodeFuse-13B.pdf)
* [CROSSCODEEVAL: A Diverse and Multilingual Benchmark for Cross-File Code Completion](./LLM/CrossCodeEval.pdf)
* [CRUXEval-X: A Benchmark for Multilingual Code Reasoning, Understanding and Execution](./LLM/CRUXEval-X.pdf)
* [CRUXEval: A Benchmark for Code Reasoning, Understanding and Execution](./LLM/CRUXEval.pdf)
* [DeepSeek-Coder: When the Large Language Model Meets Programming &ndash; The Rise of Code Intelligence](./LLM/DeepSeek-Coder.pdf)
* [DemoCraft: Using In-Context Learning to Improve Code Generation in Large Language Models](./LLM/DemoCraft.pdf)
* [Efficient Training of Language Models to Fill in the Middle](./LLM/Efficient%20Training%20of%20Language%20Models%20to%20Fill%20in%20the%20Middle.pdf)
* [Evaluating Large Language Models Trained on Code](./LLM/Evaluating%20Large%20Language%20Models%20Trained%20on%20Code.pdf)
* [Evaluation of LLMs on Syntax-Aware Code Fill-in-the-Middle Tasks](./LLM/Evaluation%20of%20LLMs%20on%20Syntax-Aware%20Code%20Fill-in-the-Middle%20Tasks.pdf)
* [InterTrans: Leveraging Transitive Intermediate Translations to Enhance LLM-based Code Translation](./LLM/InterTrans.pdf)
* [LLM-Eval: Unified Multi-Dimensional Automatic Evaluation for Open-Domain Conversations with Large Language Models](./LLM/LLM-Eval.pdf)
* [McEval: Massively Multilingual Code Evaluation](./LLM/McEval.pdf)
* [Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism](./LLM/Megatron-LM.pdf)
* [Qwen2.5-Coder Technical Report](./LLM/Qwen2.5-Coder%20Technical%20Report.pdf)
* [SGLang: Efficient Execution of Structured Language Model Programs](./LLM/SGLang.pdf)

## [Neural Network](./neural%20network/)

* [Intention Recognition with Recurrent Neural Networks for Dynamic Human-Robot Collaboration](./neural%20network/Intention_Recognition_with_Recurrent_Neural_Networks_for_Dynamic_Human-Robot_Collaboration.pdf)

## [NLP](./NLP/)

* [Dual-Objective Fine-Tuning of BERT for Entity Matching](./NLP/Dual-Objective%20Fine-Tuning%20of%20BERT%20for%20Entity%20Matching.pdf)
* [Few-Shot Intent Detection via Contrastive Pre-Training and Fine-Tuning](./NLP/Few-Shot%20Intent%20Detection%20via%20Contrastive%20Pre-Training%20and%20Fine-Tuning.pdf)
* [Intent-Aware Dialogue Generation and Multi-Task Contrastive Learning for Multi-Turn Intent Classification](./NLP/Intent-Aware%20Dialogue%20Generation%20and%20Multi-Task%20Contrastive%20Learning%20for%20Multi-Turn%20Intent%20Classification.pdf)
* [LARA: Lingustic-Adaptive Retrieval-Augmentation for Multi-Turn Intent Classification](./NLP/LARA%20Linguistic-Adaptive%20Retrieval-Augmentation%20for%20Multi-Turn%20Intent%20Classification.pdf)
* [MIDLM: Multi-Intent Detection with Bidirectional Large Language Models](./NLP/MIDLM%20Multi-Intent%20Detection%20with%20Bidirectional%20Large%20Language%20Models.pdf)
* [基于多任务蒸馏的意图识别和槽位填充](./NLP/基于多任务蒸馏的意图识别和槽位填充.pdf)

## [Transformer Model](./transformer%20model/)

* [Attention is All You Need](./transformer%20model/Attention%20is%20All%20You%20Need.pdf) ([Reading Notes](../reading%20notes/papers/Attention%20is%20All%20You%20Need.md))
* [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](./transformer%20model/BERT%20Pre-training%20of%20Deep%20Bidirectional%20Transformers%20for%20Language%20Understanding.pdf)
* [Transformed-based Map Matching Model with Limited Ground-Truth Data using Transfer-Learning Approach](./transformer%20model/Transformer-based%20Map%20Matching%20Model%20with%20Limited%20Ground-Truth%20Data%20using%20Transfer-Learning%20Approach.pdf)
* [Transformer++](./transformer%20model/Transformer++.pdf)
* [Transformers: State-of-the-Art Natural Language Processing](./transformer%20model/Transformers%20State-of-the-Art%20Natural%20Language%20Processing.pdf)